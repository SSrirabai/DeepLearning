{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzzK2R2EpXBEc2pX+m0uUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSrirabai/DeepLearning/blob/main/DeepLab3Plus_Base_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "!pip install segmentation-models-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG33ioEtCSdV",
        "outputId": "c744fd85-46ad-4449-934e-8b4094fb2726"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.24.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (10.4.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.0+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the DeepLab3+ base model\n"
      ],
      "metadata": {
        "id": "gh6FZZg0BThm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>Model Architechture</summary>\n",
        "  \n",
        "  - Model Definition: DeepLabV3Plus with 3 input channels.\n",
        "  \n",
        "  - Traning Setup\n",
        "        - num_epochs = 50\n",
        "        - eary stop mechanism kicks in when improvement_tolerance = 0.00001 is not satisfied.  #  Need to add to the code.\n",
        "        - learning_rate = 0.001\n",
        "        - patience = 3 # number of epochs with no change before early stop\n",
        "        - criterion = nn.CrossEntropyLoss()\n",
        "        - optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        - scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  \n",
        "  - Saver the initial state of the model before training\n",
        "        - When loaded before each experiment will reset the state of the model and reinitialize optimizer and learning rate schedulers\n",
        "          \n",
        "  - Evaluation Metrics\n",
        "        - Dice Coefficient (F1 Score)\n",
        "        - Jaccard\n",
        "        - Precision\n",
        "        - Recall\n",
        "        - Accuracy\n",
        "        - Loss\n",
        "</details>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uZhaZNB5BXiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score\n",
        "from albumentations import Compose as AlbCompose, Resize as AlbResize, Normalize as AlbNormalize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import DeepLabV3+ Model\n",
        "from segmentation_models_pytorch import DeepLabV3Plus"
      ],
      "metadata": {
        "id": "-qknWVLBjGxB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code that shold work\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define device and initialize DeepLabV3+ Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DeepLabV3Plus(encoder_name=\"resnet50\", encoder_weights=\"imagenet\", in_channels=3, classes=2)\n",
        "model.to(device)\n",
        "\n",
        "# Function to save the initial state of the model\n",
        "def save_initial_model_state():\n",
        "    torch.save(model.state_dict(), 'initial_deeplab_model.pth')\n",
        "    print(\"Initial model state saved!\")\n",
        "\n",
        "# Save the initial state of the model before training\n",
        "save_initial_model_state()\n",
        "\n",
        "# Training setup\n",
        "#num_epochs = 5  # use for testing the code.\n",
        "num_epochs = 50  # normally 50 epochs\n",
        "learning_rate = 0.001\n",
        "improvement_tolerance = 0.0001  # Minimum improvement required to reset the counter\n",
        "patience = 3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize metric lists to store the results.\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "train_jaccards, test_jaccards = [], []\n",
        "train_precisions, test_precisions = [], []\n",
        "train_recalls, test_recalls = [], []\n",
        "train_dices, test_dices = [], []\n",
        "\n",
        "# Data transformations\n",
        "def get_transforms():\n",
        "    return AlbCompose([\n",
        "        AlbResize(height=256, width=256, interpolation=1),  # 1 corresponds to 'bilinear'\n",
        "        AlbNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "# Dataset Class\n",
        "class KvasirDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, file_list, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        with open(file_list, 'r') as f:\n",
        "            self.image_filenames = f.read().splitlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(os.path.join(self.images_dir, self.image_filenames[idx] + '.jpg')).convert(\"RGB\")\n",
        "        mask = Image.open(os.path.join(self.masks_dir, self.image_filenames[idx] + '.png')).convert(\"L\")\n",
        "\n",
        "        # Convert images to numpy arrays\n",
        "        image_np = np.array(image)\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image_np, mask=mask_np)  # Use the correct keyword arguments\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        mask = (mask > 0).astype(np.int64)  # Convert mask to binary (0 or 1)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # Change shape to C x H x W\n",
        "        mask = torch.tensor(mask, dtype=torch.long)  # Keep mask as long for class indices\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Load datasets and define data loaders\n",
        "train_dataset = KvasirDataset('kvasir-instrument/images/', 'kvasir-instrument/masks/', 'kvasir-instrument/train.txt', transform=get_transforms())\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_dataset = KvasirDataset('kvasir-instrument/images/', 'kvasir-instrument/masks/', 'kvasir-instrument/test.txt', transform=get_transforms())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Metrics functions\n",
        "def calculate_accuracy(preds, targets):\n",
        "    correct = (preds == targets).float()\n",
        "    accuracy = correct.sum() / correct.numel()\n",
        "    return accuracy\n",
        "\n",
        "def calculate_metrics(preds, targets):\n",
        "    \"\"\"Calculate Jaccard, Precision, Recall, Accuracy, and Dice Coefficient for binary classification.\"\"\"\n",
        "    preds_flat = preds.flatten()\n",
        "    targets_flat = targets.flatten()\n",
        "    jaccard = jaccard_score(targets_flat, preds_flat, average='binary')\n",
        "    precision = precision_score(targets_flat, preds_flat, zero_division=0)\n",
        "    recall = recall_score(targets_flat, preds_flat, zero_division=0)\n",
        "    accuracy = (preds_flat == targets_flat).sum() / len(targets_flat)\n",
        "\n",
        "    # Dice Coefficient as F1 Score in binary case\n",
        "    dice = f1_score(targets_flat, preds_flat, average='binary')\n",
        "\n",
        "    return jaccard, precision, recall, accuracy, dice\n",
        "# Training function with early stopping using improvement tolerance\n",
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    best_test_loss = float('inf')\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, running_acc = 0.0, 0.0\n",
        "        all_train_jaccard, all_train_precision, all_train_recall, all_train_dice = [], [], [], []\n",
        "\n",
        "        for images, masks in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            running_loss += loss.item()\n",
        "            running_acc += calculate_accuracy(preds, masks).item()\n",
        "\n",
        "            # Calculate training metrics\n",
        "            jaccard, precision, recall, _, dice = calculate_metrics(preds.cpu().numpy(), masks.cpu().numpy())\n",
        "            all_train_jaccard.append(jaccard)\n",
        "            all_train_precision.append(precision)\n",
        "            all_train_recall.append(recall)\n",
        "            all_train_dice.append(dice)\n",
        "\n",
        "        # Log training metrics\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        avg_train_acc = running_acc / len(train_loader)\n",
        "        avg_train_jaccard = sum(all_train_jaccard) / len(all_train_jaccard)\n",
        "        avg_train_precision = sum(all_train_precision) / len(all_train_precision)\n",
        "        avg_train_recall = sum(all_train_recall) / len(all_train_recall)\n",
        "        avg_train_dice = sum(all_train_dice) / len(all_train_dice)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracies.append(avg_train_acc)\n",
        "        train_jaccards.append(avg_train_jaccard)\n",
        "        train_precisions.append(avg_train_precision)\n",
        "        train_recalls.append(avg_train_recall)\n",
        "        train_dices.append(avg_train_dice)\n",
        "\n",
        "        # Validation/Test Step\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            running_test_loss, running_test_acc = 0.0, 0.0\n",
        "            all_jaccard, all_precision, all_recall, all_accuracy, all_dice = [], [], [], [], []\n",
        "\n",
        "            for images, masks in test_loader:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                outputs = model(images)\n",
        "                test_loss = criterion(outputs, masks)\n",
        "                running_test_loss += test_loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                jaccard, precision, recall, accuracy, dice = calculate_metrics(preds.cpu().numpy(), masks.cpu().numpy())\n",
        "                all_jaccard.append(jaccard)\n",
        "                all_precision.append(precision)\n",
        "                all_recall.append(recall)\n",
        "                all_accuracy.append(accuracy)\n",
        "                all_dice.append(dice)\n",
        "\n",
        "            # Average metrics\n",
        "            avg_test_loss = running_test_loss / len(test_loader)\n",
        "            avg_test_acc = sum(all_accuracy) / len(all_accuracy)\n",
        "            avg_jaccard = sum(all_jaccard) / len(all_jaccard)\n",
        "            avg_precision = sum(all_precision) / len(all_precision)\n",
        "            avg_recall = sum(all_recall) / len(all_recall)\n",
        "            avg_dice = sum(all_dice) / len(all_dice)\n",
        "\n",
        "            # Log test metrics\n",
        "            test_losses.append(avg_test_loss)\n",
        "            test_accuracies.append(avg_test_acc)\n",
        "            test_jaccards.append(avg_jaccard)\n",
        "            test_precisions.append(avg_precision)\n",
        "            test_recalls.append(avg_recall)\n",
        "            test_dices.append(avg_dice)\n",
        "\n",
        "            # Print metrics after each epoch\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}]:\")\n",
        "            print(f\"  Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.4f}, Train Jaccard: {avg_train_jaccard:.4f}, Train Precision: {avg_train_precision:.4f}, Train Recall: {avg_train_recall:.4f}, Train Dice: {avg_train_dice:.4f}\")\n",
        "            print(f\"  Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.4f}, Jaccard: {avg_jaccard:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, Dice: {avg_dice:.4f}\")\n",
        "\n",
        "            # Check for early stopping with improvement tolerance\n",
        "            if avg_test_loss < best_test_loss - improvement_tolerance:\n",
        "                best_test_loss = avg_test_loss\n",
        "                early_stop_counter = 0\n",
        "                torch.save({'model_state_dict': model.state_dict(),\n",
        "                             'optimizer_state_dict': optimizer.state_dict(),\n",
        "                             'epoch': epoch + 1,\n",
        "                             'test_loss': avg_test_loss,\n",
        "                             'test_accuracy': avg_test_acc,\n",
        "                             'jaccard': avg_jaccard,\n",
        "                             'precision': avg_precision,\n",
        "                             'recall': avg_recall,\n",
        "                             'dice': avg_dice}, 'deeplab_best_model.pth')\n",
        "                print(\"Best model saved!\")\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "\n",
        "            if early_stop_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1} due to lack of improvement.\")\n",
        "                break\n",
        "        scheduler.step()\n",
        "\n",
        "    # Return all metrics for plotting\n",
        "    return (train_losses, test_losses, train_accuracies, test_accuracies,\n",
        "            train_jaccards, test_jaccards, train_precisions, test_precisions,\n",
        "            train_recalls, test_recalls, train_dices, test_dices)\n",
        "\n",
        "\n",
        "# Plot Loss and Accuracy.\n",
        "def plot_loss_and_accuracy(train_losses, test_losses, train_accuracies, test_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "\n",
        "    # Plot Losses\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, test_losses, label='Testing Loss')\n",
        "    plt.title('Training and Testing Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(epochs, test_accuracies, label='Testing Accuracy')\n",
        "    plt.title('Training and Testing Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plotting function update to include Dice Coefficient\n",
        "def plot_combined_metrics(\n",
        "    train_jaccard, test_jaccard,\n",
        "    train_precision, test_precision,\n",
        "    train_recall, test_recall,\n",
        "    train_dice, test_dice,\n",
        "    title='Combined Metrics Plot'\n",
        "):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Jaccard\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(train_jaccard, label='Train Jaccard', color='blue')\n",
        "    plt.plot(test_jaccard, label='Test Jaccard', color='orange')\n",
        "    plt.title('Jaccard Index')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Jaccard Score')\n",
        "    plt.legend()\n",
        "\n",
        "    # Precision\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(train_precision, label='Train Precision', color='green')\n",
        "    plt.plot(test_precision, label='Test Precision', color='red')\n",
        "    plt.title('Precision')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Precision Score')\n",
        "    plt.legend()\n",
        "\n",
        "    # Recall\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(train_recall, label='Train Recall', color='purple')\n",
        "    plt.plot(test_recall, label='Test Recall', color='brown')\n",
        "    plt.title('Recall')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Recall Score')\n",
        "    plt.legend()\n",
        "\n",
        "    # Dice\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(train_dice, label='Train Dice', color='pink')\n",
        "    plt.plot(test_dice, label='Test Dice', color='gray')\n",
        "    plt.title('Dice Coefficient')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dice Score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKIXXsFqNHqx",
        "outputId": "37bab98a-58fa-4285-9e81-a392801967b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial model state saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call the functions train, evaluate and plot results.\n"
      ],
      "metadata": {
        "id": "_NiH-Nf5RV_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training, evaluation and safe results\n",
        "results = train_and_evaluate(model, train_loader, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lMT3dHYNM3O",
        "outputId": "918ef475-ce79-43b4-90b5-cde0aca90fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 59/59 [02:03<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50]:\n",
            "  Train Loss: 0.1658, Train Accuracy: 0.9347, Train Jaccard: 0.6198, Train Precision: 0.7683, Train Recall: 0.7616, Train Dice: 0.7486\n",
            "  Test Loss: 0.0890, Test Accuracy: 0.9666, Jaccard: 0.7098, Precision: 0.7810, Recall: 0.8843, Dice: 0.8266\n",
            "Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50:  92%|█████████▏| 54/59 [01:37<00:09,  1.86s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the results to CSV File and Plot results."
      ],
      "metadata": {
        "id": "cGZ6UTXERXv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the metrics to a CSV file\n",
        "with open('training_results.csv', mode='w', newline='') as csvfile:\n",
        "    fieldnames = [\"Epoch\", \"Train Loss\", \"Test Loss\", \"Train Accuracy\",\n",
        "                  \"Test Accuracy\", \"Train Jaccard\", \"Test Jaccard\",\n",
        "                  \"Train Precision\", \"Test Precision\", \"Train Recall\",\n",
        "                  \"Test Recall\", \"Train Dice\", \"Test Dice\"]\n",
        "\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write the rows\n",
        "    for epoch in range(len(train_losses)):\n",
        "        writer.writerow({\n",
        "            \"Epoch\": epoch + 1,\n",
        "            \"Train Loss\": train_losses[epoch],\n",
        "            \"Test Loss\": test_losses[epoch],\n",
        "            \"Train Accuracy\": train_accuracies[epoch],\n",
        "            \"Test Accuracy\": test_accuracies[epoch],\n",
        "            \"Train Jaccard\": train_jaccards[epoch],\n",
        "            \"Test Jaccard\": test_jaccards[epoch],\n",
        "            \"Train Precision\": train_precisions[epoch],\n",
        "            \"Test Precision\": test_precisions[epoch],\n",
        "            \"Train Recall\": train_recalls[epoch],\n",
        "            \"Test Recall\": test_recalls[epoch],\n",
        "            \"Train Dice\": train_dices[epoch],\n",
        "            \"Test Dice\": test_dices[epoch],\n",
        "        })\n",
        "\n",
        "# Unpack results for plotting\n",
        "train_losses, test_losses, train_accuracies, test_accuracies, train_jaccards, test_jaccards, train_precisions, test_precisions, train_recalls, test_recalls, train_dices, test_dices = results\n",
        "\n",
        "# Plotting\n",
        "plot_loss_and_accuracy(train_losses, test_losses, train_accuracies, test_accuracies)\n",
        "plot_combined_metrics(train_jaccards, test_jaccards,\n",
        "                      train_precisions, test_precisions,\n",
        "                      train_recalls, test_recalls,\n",
        "                      train_dices, test_dices,\n",
        "                      title='Combined Metrics Plot')"
      ],
      "metadata": {
        "id": "iOdNwlicNU3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLGO3yo4NbOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFB0izx7NbIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhEkK5ugNbE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHZj_gq3Na9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeSXXOieNatx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}